{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b98354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pinecone 6.0.2 does not provide the extra 'async'\n"
     ]
    }
   ],
   "source": [
    "# !pip install -qU \\\n",
    "#     langchain==0.3.23 \\\n",
    "#     langchain-community==0.3.21 \\\n",
    "#     langchain-pinecone==0.2.5 \\\n",
    "#     langchain-openai==0.3.12 \\\n",
    "#     datasets==3.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58440633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Theory is a complex and abstract concept in physics that attempts to reconcile quantum mechanics with general relativity. It proposes that the fundamental constituents of the universe are not point-like particles, but rather one-dimensional \"strings\" - basically tiny loops of string.\n",
      "\n",
      "These strings vibrate at different frequencies, and these vibrations are what create the various particles that make up the universe, such as electrons, photons, and quarks. \n",
      "\n",
      "In essence, String Theory posits that everything in the universe is made up of these tiny strings, and the properties of particles (like mass and charge) are determined by the way these strings vibrate. Different vibration patterns correspond to different particle types.\n",
      "\n",
      "The theory also predicts the existence of extra dimensions beyond the three we experience daily (length, width, height), which are compactified or rolled up at very small scales.\n",
      "\n",
      "String theory is an active area of research in theoretical physics, but it's important to note that it remains a theoretical framework, as it has not yet been confirmed by experimental evidence. This is partly because the energy levels required to test these theories directly are far beyond our current technological capabilities. \n",
      "\n",
      "It's a fascinating topic, and if you want to learn more, I would recommend looking into some introductory books or online courses on the subject. Would you like me to provide some resources for further reading?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     openai_api_key=\"sk-669dc1afbce54ccaaecdd27b320777fd\",\n",
    "#     openai_api_base=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "#     model=\"qwen-turbo\"\n",
    "# )\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "#     HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "#     AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "#     HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "# ]\n",
    "\n",
    "# response = chat(messages)\n",
    "# print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b96dadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from dashvector import Client as DashClient, Doc\n",
    "\n",
    "# Step 1: Setup DashScope OpenAI-compatible client\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-91d59f4cf5ff44cf9f8280a91dacbb1c\",\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "\n",
    "dashvector_client = DashClient(\n",
    "    api_key=\"sk-eAO7D10gZP2kzhjeKmiI7b6bOHTmoD6B9CAC6318F11F097B99A92126D810D\",\n",
    "    endpoint=\"vrs-sg-l0z49hq250003n.dashvector.ap-southeast-1.aliyuncs.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b185216",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the coverage limit for Third-Party liability under Comprehensive Cover?\"\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-v3\",\n",
    "    input=query,\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "query_embedding = response.data[0].embedding  # Extract the embedding\n",
    "query_embedding = np.array(response.data[0].embedding)\n",
    "query_embedding = query_embedding / np.linalg.norm(query_embedding)  # L2 normalize\n",
    "# Ensure embeddings are lists of floats (not arrays)\n",
    "query_embedding = [float(x) for x in query_embedding]  # Convert numpy array to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53ad9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Search DashVector for top 5 similar docs\n",
    "collection = dashvector_client.get(name=\"quickstart\")\n",
    "search_results = collection.query(query_embedding, topk=10)  # Increase topk to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3a530e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coverage limit for Third-Party liability under Comprehensive Cover is up to MYR 1,000,000 per claim.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract retrieved chunks (assuming `fields` exist in result docs)\n",
    "retrieved_chunks = [doc.fields[\"text\"] for doc in search_results]\n",
    "\n",
    "# Step 4: Prepare prompt for Qwen with retrieved context + question\n",
    "context_text = \"\\n---\\n\".join(retrieved_chunks)\n",
    "\n",
    "prompt = f\"\"\"You are an AI assistant specialized in answering questions about insurance policies.\n",
    "Your task is to provide accurate answers based solely on the provided context from the policy document.\n",
    "If the context does not contain the answer, respond with \"The information is not available in the provided documents.\n",
    "\n",
    "Based on the following context:\n",
    "\n",
    "{''.join([f'[{j+1}] {chunk}' for j, chunk in enumerate(retrieved_chunks)])}\n",
    "\n",
    "Answer the question:\n",
    "{query}\n",
    "\n",
    "Instructions:\n",
    "- Use only the context above to formulate your answer.\n",
    "- If the answer is unclear, state that it is not found in the provided context.\n",
    "\"\"\"\n",
    "\n",
    "# Step 5: Call Qwen model for completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
